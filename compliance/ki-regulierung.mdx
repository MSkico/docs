---
title: 'KI-Regulierung'
description: 'Das Wichtigste zum EU AI Act.'
---

Der EU AI Act ist die weltweit erste umfassende Verordnung zur Regulierung von Künstlicher Intelligenz. Er verfolgt einen risikobasierten Ansatz und verpflichtet Entwickler sowie Betreiber von KI-Systemen zur Einhaltung transparenter, fairer und sicherer Rahmenbedingungen – insbesondere bei sensiblen Anwendungsbereichen wie dem Recruiting.

## Ab wann gilt der EU AI Act?

**Inkrafttreten:** `1. August 2024`

Obwohl der EU AI Act bereits im Sommer 2024 inkraftgetreten ist, erfolgt die Umsetzung über einen dreijährigen Zeitraum. Ab 
August 2027 gilt dann der volle Umfang des EU AI Act in allen EU-Mitgliedstaaten. 

## Zeitplan für die Umsetzung

<table class="table-auto w-full text-left border-separate border-spacing-y-4">
  <thead>
    <tr class="text-sm text-gray-700 font-semibold">
      <th class="pr-6">Phase</th>
      <th class="pr-6">Datum</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Verbot „unvertretbarer Risiken“</td>
      <td>1. Februar 2025</td>
    </tr>
    <tr>
      <td>Freiwillige Leitlinien für Entwickler</td>
      <td>1. Mai 2025</td>
    </tr>
    <tr>
      <td>Vorschriften für General-Purpose-AI</td>
      <td>1. August 2025</td>
    </tr>
    <tr>
      <td>Transparenzpflichten</td>
      <td>1. August 2026</td>
    </tr>
    <tr>
      <td>High-Risk-Vorgaben verpflichtend</td>
      <td>1. August 2027</td>
    </tr>
  </tbody>
</table>

Der EU AI Act unterteilt KI-Systeme in vier Risikoklassen – abhängig davon, wie stark sie Grundrechte, Sicherheit oder 
gesellschaftliche Werte beeinträchtigen können. Die KI-Systeme, die beispielsweise zur sozialen Bewertung von Personen ("Social Scoring")
eingesetzt werden können, stellen unvertretbare Risiken dar und sind bereits verboten. KI-Anwendungen mit minimalen oder begrenztem
Risiko, wie KI-Chatbots als Kundenservice, müssen insbesondere Transparenzpflichten erbringen. Die KI-Lösungen, die in den 
nächsten Jahren unsere Lebens- und Arbeitswelt nachhaltig ändern werden, fallen in die Kategorie mit hohem Risiko.

<Check>Du musst dir um regulatorische Risiken keine Sorgen machen. Wir tragen als Anbieter
 die Verantwortung und sorgen für eine rechtskonforme, sichere Umsetzung.</Check>

## Was sind High-Risk-Systeme? ##

Der EU AI Act definiert viele Anwendungsbereiche als solche mit hohem Risiko (woran es von Seiten der Praxis und Wissenschaft 
auch anhaltende Kritik gibt). KI-Systeme, die in sensiblen Bereichen wie Bildung, Strafverfolgung, 
Gesundheitswesen oder Recruiting eingesetzt werden, fallen in diese Kategorie. 

<Info> Da Begriffe mächtig sind und unsere Einstellung beeinflussen, plädieren wir für 
ausgewogenere Bezeichnungen, die nicht ausschließlich die Risiken betonen. Wir verstehen diese Systeme daher 
vielmehr als <strong>High Impact AI</strong> – leistungsstarke Anwendungen, die verantwortungsvoll gestaltet sein müssen, um ihr
 Potenzial fair und sicher auszuschöpfen. </Info>

## Was bedeutet das für dich als Nutzer:in? ##

Unternehmen, die KI-Systeme mit hohem Risiko nutzen, müssen bestimmte Anforderungen erfüllen, bspw. die Systemverwendung 
dokumentieren. Bis zum August 2027 werden noch weitere Konkretisierungen und Leitfäden von Seiten der Europäischen Kommission 
sowie der nationalen KI-Aufsichtsbehörde (die in Deutschland noch nicht definiert ist) erarbeitet, die diese Anforderungen 
genauer definieren. Bis dahin müssen von deiner Seite keine weiteren Schritte unternommen werden. Wir halten jegliche Neuerungen 
in diesem Bereich genau im Auge und stellen bereits jetzt sicher, dass unsere Prozesse und Systeme im Einklang mit den 
Vorgaben des EU AI Acts entwickelt werden (z.B. Human-in-the-Loop Prinzipien, etc.).

[comment]: <> (Mod)